{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW02 Code\n",
    "\n",
    "### Name: Your name here\n",
    "\n",
    "You will complete the following notebook, as described in the PDF for Homework 02 (included in the download with the starter code).  You will submit:\n",
    "1. This notebook file, along with your COLLABORATORS.txt file, to the Gradescope link for code.\n",
    "2. A PDF of this notebook and all of its output, once it is completed, to the Gradescope link for the PDF.  (This can be generated by printing the notebook as PDF, or using the **File -> Download as** menu.)\n",
    "\n",
    "\n",
    "Please report any questions to the [class Piazza page](https://piazza.com/tufts/spring2020/comp135/home)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries as needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting function\n",
    "\n",
    "**Do not modify the following**: it takes in a list of polynomial (integer) values, along with associated lists consisting of the predictions made for the associated model, and the resulting error, and plots the results in a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(polynomials=list(), prediction_list=list(), error_list=list()):\n",
    "    '''Plot predicted results for a number of polynomial regression models\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    polynomials : list of positive integer values\n",
    "        Each value is the degree of a polynomial regression model.\n",
    "    prediction_list: list of arrays ((# polynomial models) x (# input data))\n",
    "        Each array contains the predicted y-values for input data.\n",
    "    error_list: list of error values ((# polynomial models) x 1)\n",
    "        Each value is the mean squared error (MSE) of the model with \n",
    "        the associated polynomial degree.\n",
    "    \n",
    "        Note: it is expected that all lists are of the same length, and \n",
    "            that this length be some perfect square (for grid-plotting).\n",
    "    '''\n",
    "    length = len(prediction_list)\n",
    "    grid_size = int(math.sqrt(length))\n",
    "    if not (length == len(polynomials) and length == len(error_list)):\n",
    "        raise ValueError(\"Input lists must be of same length\")\n",
    "    if not length == (grid_size * grid_size):\n",
    "        raise ValueError(\"Need a square number of list items (%d given)\" % (length))\n",
    "    \n",
    "    fig, axs = plt.subplots(grid_size, grid_size, figsize =(14,14), sharey=True)\n",
    "    for subplot_id, prediction in enumerate(prediction_list):\n",
    "        # order data for display\n",
    "        data_frame = pd.DataFrame(data=[x[:, 0], prediction]).T\n",
    "        data_frame = data_frame.sort_values(by=0)\n",
    "        x_sorted = data_frame.iloc[:, :-1].values\n",
    "        prediction_sorted = data_frame.iloc[:, 1].values\n",
    "\n",
    "        ax = axs.flat[subplot_id]\n",
    "        ax.set_title('degree = %d; MSE = %.3f' % (polynomials[subplot_id], error_list[subplot_id]))\n",
    "        ax.plot(x, y, 'r.')\n",
    "        ax.plot(x_sorted, prediction_sorted, color='blue')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test a range of polynomial functions fit to the data\n",
    "\n",
    "Fit models to data of polynomial degree $d \\in \\{1, 2, 3, 4, 5, 6, 10, 11, 12\\}$.  For each such model, we will record its predictions on the input data, along with the mean squared error (MSE) that it makes.  These results are then plotted for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Create function to generate models, make predictions, measure error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_polynomials(polynomials=list()):\n",
    "    '''Generates a series of polynomial regression models on input data.\n",
    "       Each model is fit to the data, then used to predict values of that\n",
    "       input data.  Predictions and mean squared error are collected and\n",
    "       returned as two lists.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    polynomials : list of positive integer values\n",
    "        Each value is the degree of a polynomial regression model, to be built.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    prediction_list: list of arrays ((# polynomial models) x (# input data))\n",
    "        Each array contains the predicted y-values for input data.\n",
    "    error_list: list of error values ((# polynomial models) x 1)\n",
    "        Each value is the mean squared error (MSE) of the model with \n",
    "        the associated polynomial degree.\n",
    "    '''\n",
    "    prediction_list = list()\n",
    "    error_list = list()\n",
    "   \n",
    "    # TODO: fill in this function to generate the required set of models,\n",
    "    #       returning the predictions and the errors for each.\n",
    "        \n",
    "    return prediction_list, error_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate the sequence of degrees, call test_polynomials to create models,\n",
    "#       use plot_predictions to show the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Discuss the results seen in the plots above\n",
    "\n",
    "**Discussion**:  The results show... (***TODO***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. $k$-fold cross-validation \n",
    "\n",
    "For each of the polynomial degrees, 5-fold cross-validation is performed.  Data is divided into 5 equal parts, and 5 separate models are trained and tested.  Results are averaged over the 5 runs and plotted (in a single plot), comparing training and test error for each of the polynomial degrees.  Error values are also shown in a tabular form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Creating the $k$ folds\n",
    "\n",
    "A function that generates the distinct, non-overlapping folds of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folds(num_folds=1):\n",
    "    '''Splits data into num_folds separate folds for cross-validation.\n",
    "       Each fold should consist of M consecutive items from the\n",
    "       original data; each fold should be the same size (we will assume \n",
    "       that  the data divides evenly by num_folds).  Every data item should \n",
    "       appear in exactly one fold.\n",
    "       \n",
    "       Args\n",
    "       ----\n",
    "       num_folds : some positive integer value\n",
    "           Number of folds to divide data into.\n",
    "           \n",
    "        Returns\n",
    "        -------\n",
    "        x_folds : list of sub-sequences of original x-data \n",
    "            There will be num_folds such sequences; each will \n",
    "            consist of 1/num_folds of the original data, in\n",
    "            the original order.\n",
    "        y_folds : list of sub-sequences of original y data\n",
    "            There will be num_folds such sequences; each will \n",
    "            consist of 1/num_folds of the original data, in\n",
    "            the original order.\n",
    "       '''\n",
    "    x_folds = list()\n",
    "    y_folds = list()\n",
    "    \n",
    "    # TODO: Complete method to generate partition into folds.\n",
    "    \n",
    "    return x_folds, y_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out start/end of each fold for sanity check.  Should see 5 folds,\n",
    "# with the (x,y) pairs at the start/end of each.  (Can be manually verified \n",
    "# by looking at original input file.)\n",
    "#\n",
    "# DO NOT MODIFY THIS CODE.  Its output will be used to check your work.\n",
    "k = 5\n",
    "x_folds, y_folds = make_folds(k)\n",
    "for i in range(k):\n",
    "    print(\"Fold %d: (%.3f, %.3f) ... (%.3f, %.3f)\"\n",
    "         % (i, x_folds[i][0], y_folds[i][0], x_folds[i][-1], y_folds[i][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Perform cross-validation\n",
    "\n",
    "For each of the polynomial degrees already considered, $k$-fold cross-validation is performed.  Average training error (MSE) and test error (MSE) are reported, both in the form of a plot and a tabular print of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform 5-fold cross-validation for each polynomial degree.  \n",
    "#       Keep track of average training/test error for each degree; \n",
    "#       Plot results in a single table, properly labeled, and also\n",
    "#       print out the results in some clear tabular format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Discuss the results seen in the plots above\n",
    "\n",
    "**Discussion:** The results show... (***TODO***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Higher-order polynomials\n",
    "\n",
    "Results are generated and plotted (as for part 1), for the higher polynomial degrees $d = \\{15, 17, 19, 21, 25, 30, 35, 40, 50\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Plot a grid of prediction results/errors for the higher-order polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate and plot 9 more models, for the higher-degree polynomials indicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Discuss the results seen in the plots above\n",
    "\n",
    "**Discussion**: The results show... (***TODO***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regularized (ridge) regression\n",
    "\n",
    "Ridge regularization is a process whereby the loss function that is minimized combines the usual measure (error on the training data) with a penalty that is applied to the magnitude of individual coefficients.  This latter penalty discourages models that overly emphasize any single feature, and can often prevent over-fitting.\n",
    "\n",
    "Here, a set of 50 different `sklearn.linear_model.Ridge` models are generated, each using a single polynomial degree (the one that was determined to be best for the data-set in earlier tests), and using a range of different regularization penalties, chosen from a logarithmic series: $s \\in [0.01, 100]$.  5-fold cross-validation is again used to examine how robust these models are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Cross-validation for each regularization strength value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate a sequence of 50 ridge models, varying the regularization strength\n",
    "#       from 0.01 (10^-2) to 100 (10^2).  Each model is 5-fold cross-validated and\n",
    "#       the resulting average training/test errors are tracked.  Errors are then\n",
    "#       plotted (on a logarithmic scale) and printed in some legible tabular form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Discuss the results seen in the plots above\n",
    "\n",
    "**Discussion**:  The results show...  (***TODO***)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
